Status: 30/04/2015
to do:
1. Insert the dissected packet information into database.
Logic:
   a. End user( Browser Client) sending packet to the  proxy server:
               i. capture time stamp, packet size and other informations, and insert into the database
               ii. Browser Client receives packet for the corresponding send packet, i.e.( ACK). Update the timeStapm of ACK/response packet, response byte into the DB.
 Do the same for
  b. For each request <--> Response , take the start and end time stamp.( Browser Client end )
  c. Proxy server-- which is playing a double role... ( receives Request packets from the browser client & other resources, and send back the responses after some network delay( which is due WWW ).
  d. Group the Proxy servers' request , response packets by the time stamp window that has been generated by "step b".

work Done:
  1. read the json config file, that will tell the filter Ip , logFiles setting, and tcpDump files nameLocation and sfew more statics which needed to set up the environment. --tested and verified
  2. libpcap code that will take a tcpDump file at a time and will dissect, the ip address, port and so on.....  functional testing needed
  3. the interface for database... ( db creation, create the data table, and insert function)--- functional testing needed
-----------------------------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------------------------
Status: 01/05/2015
 work Done:
  1. get the timestamp from each network packet( tested)
  2. shared buffer creation-- method from sniffing.cpp will parse the date with respect to ip, and update in a data structure, then memcpy that
     struct into the sared buffer. grupPacket.cpp will read that structure(memcpy) and will group the packets with respect to conversation. Both read and 
     write are thread safe, and mutex locked.(tested)
  3. gruping the packets with respect to the conversation(groupPacket.cpp & .hpp )-- coding done--throwing some segmentation fault at method: validPacket----
  
To Do:
  1. grupPacket.cpp method validPacket --throwing segmentation fault-- need to handle
  2. have to test and validate the algorithom impllemented for grouping.
  3. store the grouped data withrespect to conversationId into sqlite3 database.( for browser end's tcpdump packet)
  4. for second or else dump files..have to just group incoming and outgoing pakets count with respect to timestamp
  5. user interface(command line) to get the enduser statstics..at present write into a file..
 
Future Scope:
  1. In buffer management--- remove memcpy-- the write method will rent an struct variable from the buffer and will write it;s data
     into that.. and read method will just access that data from that posotion--- will provide better performance
  2. GUI --- will handover to some JAVA person, who will design the GUI and call the c++ methodes.
-----------------------------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------------------------
Status: 02/05/2015
 Work Done:
 1. No segmentation fault--- ( took almost 8 hours to solve the segmentation fault )
 2. Circular Buffer was not working properly---- MOdified algorithom.
 3. New algo developed for packet grouping.-- need to test.
 4. little bit of code review

To Do:
 1. Complete dbInterface code.
 2. Insert processed information into the database, through groupPacket.cpp
 3. check the functionality of grouping packet algorithom.
 4. json file handle, for reading the configuration like. circular buffer size, array size --needed during grouping.
Note: Tom no work for this tool.
-----------------------------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------------------------
Status:04/05/2015
 Tried to fix a segmentation fault( took 7 hours but not able to fix). And changed the logic of grouping algo.
-----------------------------------------------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------------------------------------------
